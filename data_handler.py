import json
import os
import re
from datetime import datetime
import uuid
import shutil
import logging

# --- íŒŒì¼ ê²½ë¡œ ---
RAW_DATA_FILE = "kstartup_contest_info.json"
ORGS_FILE = "organizations.json"
ANNS_FILE = "announcements.json"
INDEX_FILE = "index.json"

# --- ë°ì´í„° ë¡œë“œ/ì €ì¥ í—¬í¼ í•¨ìˆ˜ ---

def load_json(filepath, default=None):
    """JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤. íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if default is None:
        default = {}
    if not os.path.exists(filepath):
        return default
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except json.JSONDecodeError:
        print(f"[ê²½ê³ ] {filepath} íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì˜ëª»ëœ í˜•ì‹ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return default
    except Exception as e:
        print(f"[ì—ëŸ¬] {filepath} ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return default

def save_json(data, filepath):
    """ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[ì—ëŸ¬] {filepath} ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- ë°ì´í„° ì²˜ë¦¬ ë° ì¸ë±ì‹± ---

def extract_deadline_from_period(application_period):
    """ì ‘ìˆ˜ê¸°ê°„ì—ì„œ ë§ˆê°ì¼ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. (YYYYMMDD ~ YYYYMMDD í˜•ì‹)"""
    if not application_period:
        return None
    
    try:
        # "20250602 ~ 20250620" í˜•ì‹ì—ì„œ ë§ˆê°ì¼(ë ë‚ ì§œ) ì¶”ì¶œ
        if '~' in application_period:
            parts = application_period.split('~')
            if len(parts) >= 2:
                end_date_str = parts[1].strip()
                # YYYYMMDD í˜•ì‹ì„ YYYY-MM-DDë¡œ ë³€í™˜
                if len(end_date_str) == 8 and end_date_str.isdigit():
                    year = end_date_str[:4]
                    month = end_date_str[4:6]
                    day = end_date_str[6:8]
                    return f"{year}-{month}-{day}"
        
        # ë‹¨ì¼ ë‚ ì§œì¸ ê²½ìš° (YYYYMMDD)
        elif len(application_period.strip()) == 8 and application_period.strip().isdigit():
            date_str = application_period.strip()
            year = date_str[:4]
            month = date_str[4:6]
            day = date_str[6:8]
            return f"{year}-{month}-{day}"
            
    except Exception as e:
        print(f"[ê²½ê³ ] ì ‘ìˆ˜ê¸°ê°„ íŒŒì‹± ì˜¤ë¥˜ ({application_period}): {e}")
    
    return None

def format_date_string(date_str):
    """YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œë¥¼ YYYY-MM-DDë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not date_str:
        return None
    
    try:
        if len(date_str) == 8 and date_str.isdigit():
            year = date_str[:4]
            month = date_str[4:6]
            day = date_str[6:8]
            return f"{year}-{month}-{day}"
    except Exception as e:
        print(f"[ê²½ê³ ] ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜ ({date_str}): {e}")
    
    return date_str  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜

def generate_org_id(org_name):
    """ê¸°ê´€ëª…ìœ¼ë¡œë¶€í„° ê°„ë‹¨í•œ ê³ ìœ  IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # ê°„ë‹¨í•˜ê²Œ ì• 3ê¸€ì + ê¸¸ì´ ì‚¬ìš© (ì¤‘ë³µ ê°€ëŠ¥ì„± ìˆìŒ, ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• í•„ìš”)
    prefix = re.sub(r'\W+', '', org_name)[:3].upper()
    return f"ORG_{prefix}{len(org_name)}"

def tokenize(text):
    """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ í† í°í™” (ë„ì–´ì“°ê¸° ê¸°ì¤€, íŠ¹ìˆ˜ë¬¸ì ì œê±°) - ì¸ë±ì‹±ìš©"""
    if not text:
        return []
    words = re.findall(r'\b\w+\b', text.lower())
    return list(set(word for word in words if len(word) > 1))

def process_raw_data():
    """
    kstartup_contest_info.jsonì„ ì½ì–´ organizations.json, announcements.json, index.json ìƒì„±/ì—…ë°ì´íŠ¸
    """
    raw_data = load_json(RAW_DATA_FILE)
    if not raw_data:
        print(f"[ì •ë³´] {RAW_DATA_FILE} íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return False

    organizations = load_json(ORGS_FILE)
    announcements = load_json(ANNS_FILE)
    index = load_json(INDEX_FILE, default={
        "title_keywords": {}, # ì œëª© í‚¤ì›Œë“œ ì¸ë±ìŠ¤ëŠ” ì—¬ì „íˆ ìƒì„± (í•„ìš”ì‹œ ë‹¤ë¥¸ ìš©ë„ë¡œ í™œìš© ê°€ëŠ¥)
        "organization_name": {},
        "region": {},
        "support_field": {},
        "pbancSn_to_orgId": {}
    })

    new_org_count = 0
    new_ann_count = 0
    updated_ann_count = 0

    org_name_to_id = {org_data["name"]: org_id for org_id, org_data in organizations.items()}

    for pbancSn_str, ann_data in raw_data.items():
        pbancSn = int(pbancSn_str)
        org_name = ann_data.get("ê³µê³ ê¸°ê´€") or ann_data.get("ê¸°ê´€ëª…")

        if not org_name:
            print(f"[ê²½ê³ ] ê³µê³  {pbancSn}ì˜ ê¸°ê´€ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        # 1. ê¸°ê´€ ì •ë³´ ì²˜ë¦¬
        org_id = org_name_to_id.get(org_name)
        if not org_id:
            org_id = generate_org_id(org_name)
            while org_id in organizations:
                org_id += "X"
            organizations[org_id] = {
                "name": org_name,
                "type": ann_data.get("ê¸°ê´€êµ¬ë¶„", "")
            }
            org_name_to_id[org_name] = org_id
            new_org_count += 1

        # 2. ê³µê³  ì •ë³´ ì²˜ë¦¬
        # ì ‘ìˆ˜ê¸°ê°„ì—ì„œ ë§ˆê°ì¼ ì¶”ì¶œ
        application_period = ann_data.get("ì ‘ìˆ˜ê¸°ê°„", "")
        deadline = extract_deadline_from_period(application_period)
        
        # ê³µê³ ì¼ì ì²˜ë¦¬
        announcement_date = ann_data.get("ê³µê³ ì¼ì", "")
        formatted_announcement_date = format_date_string(announcement_date)
        
        announcement_entry = {
            "title": ann_data.get("title", ""),
            "support_field": ann_data.get("ì§€ì›ë¶„ì•¼", ""),
            "target_age": ann_data.get("ëŒ€ìƒì—°ë ¹", ""),
            "org_name_ref": org_name,
            "org_id": org_id,
            "contact": ann_data.get("ì—°ë½ì²˜", ""),
            "region": ann_data.get("ì§€ì—­", ""),
            "application_period": application_period,
            "deadline": deadline,  # ì¶”ì¶œëœ ë§ˆê°ì¼
            "startup_experience": ann_data.get("ì°½ì—…ì—…ë ¥", ""),
            "target_audience": ann_data.get("ëŒ€ìƒ", ""),
            "department": ann_data.get("ë‹´ë‹¹ë¶€ì„œ", ""),
            "announcement_number": ann_data.get("ê³µê³ ë²ˆí˜¸", ""),
            "description": ann_data.get("ê³µê³ ì„¤ëª…", ""),
            "announcement_date": formatted_announcement_date,
            "application_method": ann_data.get("ì‹ ì²­ë°©ë²•", []),
            "submission_documents": ann_data.get("ì œì¶œì„œë¥˜", []),
            "selection_procedure": ann_data.get("ì„ ì •ì ˆì°¨", []),
            "support_content": ann_data.get("ì§€ì›ë‚´ìš©", []),
            "inquiry": ann_data.get("ë¬¸ì˜ì²˜", []),
            "attachments": ann_data.get("ì²¨ë¶€íŒŒì¼", [])
        }

        is_new = pbancSn_str not in announcements
        needs_update = not is_new and announcements[pbancSn_str] != announcement_entry

        if is_new or needs_update:
            announcements[pbancSn_str] = announcement_entry
            if is_new:
                new_ann_count += 1
            else:
                updated_ann_count += 1

            # 3. ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ (ë¶€ë¶„ ì—…ë°ì´íŠ¸ ë¡œì§ì€ ì—¬ì „íˆ ë‹¨ìˆœí™”ë¨)
            index["pbancSn_to_orgId"][pbancSn_str] = org_id

            # ì œëª© í‚¤ì›Œë“œ ì¸ë±ì‹± (ì—¬ì „íˆ ìƒì„±)
            title_tokens = tokenize(announcement_entry["title"])
            for token in title_tokens:
                if token not in index["title_keywords"]:
                    index["title_keywords"][token] = []
                if pbancSn_str not in index["title_keywords"][token]:
                     index["title_keywords"][token].append(pbancSn_str)

            # ê¸°ê´€ëª… ì¸ë±ì‹±
            if org_name:
                if org_name not in index["organization_name"]:
                    index["organization_name"][org_name] = []
                if pbancSn_str not in index["organization_name"][org_name]:
                    index["organization_name"][org_name].append(pbancSn_str)

            # ì§€ì—­ ì¸ë±ì‹±
            region = announcement_entry["region"]
            if region:
                if region not in index["region"]:
                    index["region"][region] = []
                if pbancSn_str not in index["region"][region]:
                     index["region"][region].append(pbancSn_str)

            # ì§€ì›ë¶„ì•¼ ì¸ë±ì‹±
            support_field = announcement_entry["support_field"]
            if support_field:
                fields = [f.strip() for f in support_field.split(',') if f.strip()]
                for field in fields:
                    if field not in index["support_field"]:
                        index["support_field"][field] = []
                    if pbancSn_str not in index["support_field"][field]:
                        index["support_field"][field].append(pbancSn_str)

    save_json(organizations, ORGS_FILE)
    save_json(announcements, ANNS_FILE)
    save_json(index, INDEX_FILE)

    print(f"[ì •ë³´] ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: ì‹ ê·œ ê¸°ê´€ {new_org_count}ê°œ, ì‹ ê·œ ê³µê³  {new_ann_count}ê°œ, ì—…ë°ì´íŠ¸ëœ ê³µê³  {updated_ann_count}ê°œ")
    return True

# --- CRUD í•¨ìˆ˜ ---

def get_all_organizations():
    """ëª¨ë“  ê¸°ê´€ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return load_json(ORGS_FILE)

def get_all_announcements():
    """ëª¨ë“  ê³µê³  ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return load_json(ANNS_FILE)

def get_announcement_by_id(pbancSn_str):
    """IDë¡œ íŠ¹ì • ê³µê³  ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    announcements = load_json(ANNS_FILE)
    return announcements.get(pbancSn_str)

def find_announcements(keyword=None, org_name=None, region=None, support_field=None):
    """ì¡°ê±´ì— ë§ëŠ” ê³µê³  ID ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤. í‚¤ì›Œë“œëŠ” ë¶€ë¶„ ë¬¸ìì—´ ê²€ìƒ‰, ë‚˜ë¨¸ì§€ëŠ” ì¸ë±ìŠ¤ í™œìš©."""
    index = load_json(INDEX_FILE)
    announcements = load_json(ANNS_FILE)
    if not announcements: # ê³µê³  ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê²€ìƒ‰ ë¶ˆê°€
        return []

    result_sets = []
    all_ann_ids = set(announcements.keys()) # êµì§‘í•© ì—°ì‚°ì„ ìœ„í•´ ì „ì²´ ID ì§‘í•© ìƒì„±

    # 1. í‚¤ì›Œë“œ ê²€ìƒ‰ (ë¶€ë¶„ ë¬¸ìì—´ ê²€ìƒ‰)
    if keyword:
        keyword_ids = set()
        search_keyword_lower = keyword.lower()
        for pbancSn_str, ann_data in announcements.items():
            title = ann_data.get("title", "")
            if search_keyword_lower in title.lower():
                keyword_ids.add(pbancSn_str)
        result_sets.append(keyword_ids)

    # 2. ê¸°ê´€ëª… ê²€ìƒ‰ (ì¸ë±ìŠ¤ í™œìš©)
    if org_name:
        if index and org_name in index.get("organization_name", {}):
             result_sets.append(set(index["organization_name"][org_name]))
        else: # ì¸ë±ìŠ¤ê°€ ì—†ê±°ë‚˜ ê¸°ê´€ëª…ì´ ì¸ë±ìŠ¤ì— ì—†ëŠ” ê²½ìš°
             result_sets.append(set()) # ë¹ˆ ì§‘í•© ì¶”ê°€

    # 3. ì§€ì—­ í•„í„° (ì¸ë±ìŠ¤ í™œìš©)
    if region:
        if index and region in index.get("region", {}):
            result_sets.append(set(index["region"][region]))
        else:
            result_sets.append(set())

    # 4. ì§€ì›ë¶„ì•¼ í•„í„° (ì¸ë±ìŠ¤ í™œìš©)
    if support_field:
        if index and support_field in index.get("support_field", {}):
             result_sets.append(set(index["support_field"][support_field]))
        else:
             result_sets.append(set())

    # ëª¨ë“  ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ID ì°¾ê¸° (êµì§‘í•©)
    if not result_sets: # ì ìš©ëœ í•„í„°ê°€ ì—†ìœ¼ë©´ ëª¨ë“  ê³µê³  ID ë°˜í™˜
        return list(all_ann_ids)
    else:
        # ì‹œì‘ ì§‘í•©ì„ ì „ì²´ IDë¡œ ì„¤ì •í•˜ê³ , ê° í•„í„° ê²°ê³¼ì™€ êµì§‘í•© ìˆ˜í–‰
        final_ids = all_ann_ids
        for s in result_sets:
            final_ids.intersection_update(s)
        return list(final_ids)


def update_announcement(pbancSn_str, updated_data):
    """íŠ¹ì • ê³µê³  ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. (ê°œì„ ëœ Pinecone ë©”íƒ€ë°ì´í„° í¬í•¨)"""
    try:
        # 1. JSON íŒŒì¼ ì—…ë°ì´íŠ¸
        announcements = load_json(ANNS_FILE)
        if pbancSn_str not in announcements:
            print(f"[ì—ëŸ¬] ê³µê³  ID {pbancSn_str}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° ë³‘í•©
        announcements[pbancSn_str].update(updated_data)
        
        # 2. JSON íŒŒì¼ ì €ì¥
        save_json(announcements, ANNS_FILE)
        print(f"[ì •ë³´] ê³µê³  {pbancSn_str} JSON íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ")

        # 3. ê°œì„ ëœ Pinecone ì—…ë°ì´íŠ¸
        try:
            from rag_system import _build_announcement_text, _build_announcement_metadata, get_rag_chatbot
            
            # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” í™•ì¸
            chatbot = get_rag_chatbot()
            if not chatbot.embedding_manager.model or not chatbot.pinecone_manager.index:
                print(f"[ê²½ê³ ] RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ Pinecone ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                return True  # JSON ì—…ë°ì´íŠ¸ëŠ” ì„±ê³µí–ˆìœ¼ë¯€ë¡œ True ë°˜í™˜
            
            # ì—…ë°ì´íŠ¸ëœ ë°ì´í„°ë¡œ ê°œì„ ëœ ì„ë² ë”© ë° ë©”íƒ€ë°ì´í„° ìƒì„±
            updated_contest_data = announcements[pbancSn_str]
            
            # ê°œì„ ëœ í…ìŠ¤íŠ¸ ë‚´ìš© êµ¬ì„± (ëª¨ë“  ë©”íƒ€ë°ì´í„° í¬í•¨)
            text_content = _build_announcement_text(updated_contest_data)
            
            if text_content.strip():
                # ì„ë² ë”© ìƒì„±
                embedding = chatbot.embedding_manager.create_embedding(text_content)
                
                # ê°œì„ ëœ ë©”íƒ€ë°ì´í„° êµ¬ì„± (í™•ì¥ëœ ì •ë³´ í¬í•¨)
                metadata = _build_announcement_metadata(updated_contest_data)
                
                # ë²¡í„° ë°ì´í„° êµ¬ì„±
                vector_id = f"announcement_{pbancSn_str}"
                vector_data = [{
                    "id": vector_id,
                    "values": embedding,
                    "metadata": metadata
                }]
                
                # Pineconeì— ì—…ì„œíŠ¸
                success = chatbot.pinecone_manager.upsert_vectors(vector_data)
                if success:
                    print(f"[ì •ë³´] ê³µê³  {pbancSn_str} Pinecone ì—…ë°ì´íŠ¸ ì™„ë£Œ (ê°œì„ ëœ ë©”íƒ€ë°ì´í„°)")
                else:
                    print(f"[ê²½ê³ ] ê³µê³  {pbancSn_str} Pinecone ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                    return False
            else:
                print(f"[ê²½ê³ ] ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ì—†ì–´ Pinecone ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"[ê²½ê³ ] Pinecone ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

        return True
    except Exception as e:
        print(f"[ì—ëŸ¬] ê³µê³  ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def delete_announcement(pbancSn_str):
    """íŠ¹ì • ê³µê³  ì •ë³´ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤. (ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ëŠ” ë‹¨ìˆœí™”)"""
    announcements = load_json(ANNS_FILE)
    if pbancSn_str not in announcements:
        print(f"[ì—ëŸ¬] ê³µê³  ID {pbancSn_str}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    del announcements[pbancSn_str]
    save_json(announcements, ANNS_FILE)

    # TODO: ì¸ë±ìŠ¤ì—ì„œ í•´ë‹¹ pbancSn ì œê±°í•˜ëŠ” ë¡œì§ í•„ìš”
    # ì—¬ê¸°ì„œëŠ” index.jsonì€ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ
    # process_raw_data() # ë¹„íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŒ. ë¶€ë¶„ ì—…ë°ì´íŠ¸ ë¡œì§ í•„ìš”.
    print(f"[ì •ë³´] ê³µê³  {pbancSn_str} ì‚­ì œ ì™„ë£Œ. (ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ í•„ìš”ì‹œ process_raw_data() ì¬ì‹¤í–‰ ê¶Œì¥)")
    return True


# --- ì´ˆê¸°í™” ---
# í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ ë°ì´í„° íŒŒì¼ë“¤ì´ ì—†ìœ¼ë©´ ìƒì„± ì‹œë„
def initialize_data():
    """ë°ì´í„° íŒŒì¼ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™” (raw ë°ì´í„° ì²˜ë¦¬) ì‹œë„"""
    if not os.path.exists(ORGS_FILE) or not os.path.exists(ANNS_FILE) or not os.path.exists(INDEX_FILE):
        print("[ì •ë³´] ë°ì´í„° íŒŒì¼(organizations, announcements, index)ì´ ì—†ìŠµë‹ˆë‹¤. raw ë°ì´í„° ì²˜ë¦¬ë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
        if os.path.exists(RAW_DATA_FILE):
            process_raw_data()
        else:
            print(f"[ê²½ê³ ] {RAW_DATA_FILE} íŒŒì¼ì´ ì—†ì–´ ì´ˆê¸° ë°ì´í„° êµ¬ì¡°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # ë¹ˆ íŒŒì¼ì´ë¼ë„ ìƒì„±
            save_json({}, ORGS_FILE)
            save_json({}, ANNS_FILE)
            save_json({}, INDEX_FILE)

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ
DATA_FILE = 'kstartup_contest_info.json'

# ë©”ëª¨ë¦¬ì— ë¡œë“œëœ ì „ì²´ ê³µê³  ë°ì´í„°
all_contests_data = []

def load_all_data():
    """
    JSON íŒŒì¼ë“¤ì—ì„œ ëª¨ë“  ê³µê³  ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ all_contests_dataì— ì €ì¥í•©ë‹ˆë‹¤.
    announcements.jsonì´ ë” ë§ì€ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©´ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    global all_contests_data
    
    print("\n[LOAD] ==================== ë°ì´í„° ë¡œë“œ ì‹œì‘ ====================")
    
    # ë°±ì—… íŒŒì¼ë“¤ í™•ì¸
    backup_files = [f for f in os.listdir('.') if f.startswith(f"{DATA_FILE}.backup.")]
    if backup_files:
        print(f"[LOAD] ë°±ì—… íŒŒì¼ {len(backup_files)}ê°œ ë°œê²¬")
    
    # 1. kstartup_contest_info.json ë¡œë“œ ì‹œë„
    contest_data = []
    contest_file_error = None
    
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
                if content.strip():
                    loaded_json = json.loads(content)
                    if isinstance(loaded_json, dict):
                        contest_data = list(loaded_json.values())
                    elif isinstance(loaded_json, list):
                        contest_data = loaded_json
                    print(f"[LOAD] kstartup_contest_info.jsonì—ì„œ {len(contest_data)}ê°œ í•­ëª© ë¡œë“œ")
                else:
                    print(f"[LOAD] {DATA_FILE}ì´ ë¹„ì–´ìˆìŒ")
        except Exception as e:
            contest_file_error = e
            print(f"[LOAD] {DATA_FILE} ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ë°±ì—…ì—ì„œ ë³µêµ¬ ì‹œë„
            if backup_files:
                print(f"[RECOVERY] ë°±ì—…ì—ì„œ ë³µêµ¬ ì‹œë„...")
                latest_backup = sorted(backup_files)[-1]
                try:
                    with open(latest_backup, 'r', encoding='utf-8') as f:
                        backup_content = json.load(f)
                        if isinstance(backup_content, dict):
                            contest_data = list(backup_content.values())
                        elif isinstance(backup_content, list):
                            contest_data = backup_content
                        print(f"[RECOVERY] ë°±ì—…ì—ì„œ {len(contest_data)}ê°œ í•­ëª© ë³µêµ¬ ì„±ê³µ: {latest_backup}")
                except Exception as backup_error:
                    print(f"[RECOVERY] ë°±ì—… ë³µêµ¬ ì‹¤íŒ¨: {backup_error}")
    
    # 2. announcements.json ë¡œë“œ ì‹œë„ (ë” ë§ì€ ë°ì´í„°ê°€ ìˆì„ ê°€ëŠ¥ì„±)
    announcements_data = []
    announcements_file_error = None
    
    if os.path.exists(ANNS_FILE):
        try:
            announcements_dict = load_json(ANNS_FILE, default={})
            if announcements_dict:
                announcements_data = list(announcements_dict.values())
                print(f"[LOAD] announcements.jsonì—ì„œ {len(announcements_data)}ê°œ í•­ëª© ë¡œë“œ")
        except Exception as e:
            announcements_file_error = e
            print(f"[LOAD] {ANNS_FILE} ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 3. ë” ë§ì€ ë°ì´í„°ë¥¼ ê°€ì§„ ì†ŒìŠ¤ ì„ íƒ
    if len(announcements_data) > len(contest_data):
        print(f"[LOAD] announcements.jsonì´ ë” ë§ì€ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆìŒ ({len(announcements_data)} vs {len(contest_data)})")
        all_contests_data = announcements_data
        
        # kstartup_contest_info.jsonì„ announcements.jsonê³¼ ë™ê¸°í™”
        if len(contest_data) < len(announcements_data):
            try:
                print(f"[SYNC] kstartup_contest_info.jsonì„ announcements.jsonê³¼ ë™ê¸°í™” ì¤‘...")
                sync_data = {}
                
                for i, item in enumerate(all_contests_data):
                    if item and isinstance(item, dict):
                        pblancId = item.get('pblancId', f"AUTO_ID_{i}")
                        if not pblancId or pblancId == 'N/A':
                            pblancId = str(uuid.uuid4())
                            item['pblancId'] = pblancId
                        sync_data[str(pblancId)] = item
                
                # ë°±ì—… ìƒì„± í›„ ë™ê¸°í™”
                if os.path.exists(DATA_FILE):
                    backup_file = f"{DATA_FILE}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    shutil.copy2(DATA_FILE, backup_file)
                    print(f"[SYNC] ë™ê¸°í™” ì „ ë°±ì—… ìƒì„±: {backup_file}")
                
                with open(DATA_FILE, 'w', encoding='utf-8') as f:
                    json.dump(sync_data, f, ensure_ascii=False, indent=2)
                
                print(f"[SYNC] ë™ê¸°í™” ì™„ë£Œ: {len(sync_data)}ê°œ í•­ëª©")
                
            except Exception as e:
                print(f"[SYNC] ë™ê¸°í™” ì‹¤íŒ¨: {e}")
    
    elif len(contest_data) > 0:
        print(f"[LOAD] kstartup_contest_info.json ì‚¬ìš© ({len(contest_data)}ê°œ í•­ëª©)")
        all_contests_data = contest_data
    
    else:
        print(f"[LOAD] ëª¨ë“  ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆìŒ")
        all_contests_data = []
        
        # ê¸´ê¸‰ ë³µêµ¬: ë°±ì—… íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        if backup_files and (contest_file_error or announcements_file_error):
            print(f"[EMERGENCY] ê¸´ê¸‰ ë³µêµ¬ ì‹œë„...")
            for backup_file in sorted(backup_files, reverse=True):  # ìµœì‹  ë°±ì—…ë¶€í„°
                try:
                    with open(backup_file, 'r', encoding='utf-8') as f:
                        backup_data = json.load(f)
                        if isinstance(backup_data, dict) and backup_data:
                            all_contests_data = list(backup_data.values())
                            print(f"[EMERGENCY] ê¸´ê¸‰ ë³µêµ¬ ì„±ê³µ: {backup_file}ì—ì„œ {len(all_contests_data)}ê°œ í•­ëª©")
                            break
                except Exception as emergency_error:
                    print(f"[EMERGENCY] {backup_file} ë³µêµ¬ ì‹¤íŒ¨: {emergency_error}")
    
    print(f"[LOAD] ìµœì¢… ë¡œë“œëœ ë°ì´í„°: {len(all_contests_data)}ê°œ í•­ëª©")
    
    # 4. ë°ì´í„° ê²€ì¦ ë° ì •ë¦¬
    valid_data = []
    fixed_count = 0
    
    for i, item in enumerate(all_contests_data):
        if isinstance(item, dict) and item.get('title'):  # ìµœì†Œí•œ ì œëª©ì´ ìˆëŠ” ë°ì´í„°ë§Œ
            # pblancIdê°€ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
            if 'pblancId' not in item or not item['pblancId'] or item['pblancId'] == 'N/A':
                item['pblancId'] = str(uuid.uuid4())
                fixed_count += 1
            valid_data.append(item)
    
    all_contests_data = valid_data
    
    print(f"[LOAD] ê²€ì¦ í›„ ìœ íš¨í•œ ë°ì´í„°: {len(all_contests_data)}ê°œ í•­ëª©")
    if fixed_count > 0:
        print(f"[LOAD] pblancId ìë™ ìˆ˜ì •: {fixed_count}ê°œ í•­ëª©")
    
    # 5. ë°ì´í„° ë¬´ê²°ì„± ìµœì¢… ê²€ì¦
    if len(all_contests_data) == 0:
        print(f"[WARNING] ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
    elif len(all_contests_data) < 10:
        print(f"[WARNING] ë¡œë“œëœ ë°ì´í„°ê°€ ì˜ˆìƒë³´ë‹¤ ì ìŠµë‹ˆë‹¤ ({len(all_contests_data)}ê°œ)")
    else:
        print(f"[SUCCESS] ë°ì´í„° ë¡œë“œ ì„±ê³µ")
    
    print(f"[LOAD] ==================== ë°ì´í„° ë¡œë“œ ì™„ë£Œ ====================\n")
    
    return len(all_contests_data)

def save_all_data():
    """
    all_contests_dataì˜ ë‚´ìš©ì„ kstartup_contest_info.json íŒŒì¼ì— ì•ˆì „í•˜ê²Œ ì €ì¥í•©ë‹ˆë‹¤.
    ë°±ì—… ìƒì„± ë° ì›ìì  ì“°ê¸°ë¥¼ í†µí•´ ë°ì´í„° ì†ì‹¤ì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    global all_contests_data
    
    print(f"\n[SAVE] ==================== ë°ì´í„° ì €ì¥ ì‹œì‘ ====================")
    print(f"[SAVE] ì €ì¥í•  ë°ì´í„° ìˆ˜: {len(all_contests_data)}")
    
    # 1. ë°ì´í„° ê²€ì¦
    if not all_contests_data:
        print(f"[ERROR] ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì €ì¥ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return False
    
    # 2. ê¸°ì¡´ íŒŒì¼ ë°±ì—… ìƒì„±
    backup_created = False
    if os.path.exists(DATA_FILE):
        try:
            backup_file = f"{DATA_FILE}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            shutil.copy2(DATA_FILE, backup_file)
            print(f"[SAVE] ë°±ì—… íŒŒì¼ ìƒì„±: {backup_file}")
            backup_created = True
        except Exception as e:
            print(f"[WARNING] ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
    
    # 3. ë°ì´í„° ë³€í™˜ (pblancIdê°€ ìˆëŠ” í•­ëª©ë§Œ)
    valid_data = {}
    invalid_count = 0
    
    for item in all_contests_data:
        if isinstance(item, dict) and 'pblancId' in item and item['pblancId']:
            pblancId = str(item['pblancId'])
            valid_data[pblancId] = item
        else:
            invalid_count += 1
    
    print(f"[SAVE] ìœ íš¨í•œ ë°ì´í„°: {len(valid_data)}ê°œ")
    if invalid_count > 0:
        print(f"[WARNING] pblancIdê°€ ì—†ëŠ” ë°ì´í„° {invalid_count}ê°œ ì œì™¸ë¨")
    
    # 4. ìµœì†Œ ë°ì´í„° ìˆ˜ ê²€ì¦ (ê¸°ì¡´ ë°ì´í„°ê°€ 10,000ê°œ ì´ìƒì´ì—ˆìœ¼ë¯€ë¡œ)
    if len(valid_data) < 100:  # ì„ê³„ì¹˜ ì„¤ì •
        print(f"[ERROR] ì €ì¥í•  ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤ ({len(valid_data)}ê°œ). ë°ì´í„° ì†ì‹¤ ë°©ì§€ë¥¼ ìœ„í•´ ì €ì¥ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return False
    
    # 5. ì„ì‹œ íŒŒì¼ì— ë¨¼ì € ì €ì¥ (ì›ìì  ì“°ê¸°)
    temp_file = f"{DATA_FILE}.tmp"
    try:
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(valid_data, f, ensure_ascii=False, indent=2)
        
        # 6. ì €ì¥ ì„±ê³µ ì‹œ ì›ë³¸ íŒŒì¼ë¡œ ì´ë™
        if os.path.exists(temp_file):
            if os.path.exists(DATA_FILE):
                os.remove(DATA_FILE)
            os.rename(temp_file, DATA_FILE)
            
            print(f"[SAVE] ë°ì´í„° ì €ì¥ ì™„ë£Œ: {len(valid_data)}ê°œ í•­ëª©")
            print(f"[SAVE] ==================== ë°ì´í„° ì €ì¥ ì™„ë£Œ ====================\n")
            return True
        else:
            print(f"[ERROR] ì„ì‹œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        print(f"[ERROR] ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(temp_file):
            try:
                os.remove(temp_file)
            except:
                pass
        
        # ë°±ì—…ì—ì„œ ë³µêµ¬ ì‹œë„
        if backup_created:
            try:
                backup_files = [f for f in os.listdir('.') if f.startswith(f"{DATA_FILE}.backup.")]
                if backup_files:
                    latest_backup = sorted(backup_files)[-1]
                    shutil.copy2(latest_backup, DATA_FILE)
                    print(f"[RECOVERY] ë°±ì—…ì—ì„œ ë³µêµ¬ ì™„ë£Œ: {latest_backup}")
            except Exception as recovery_error:
                print(f"[ERROR] ë°±ì—… ë³µêµ¬ ì‹¤íŒ¨: {recovery_error}")
        
        return False

def get_all_contests():
    """
    ë©”ëª¨ë¦¬ì— ë¡œë“œëœ ëª¨ë“  ê³µê³  ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)
    """
    global all_contests_data
    # ë°ì´í„°ê°€ ë©”ëª¨ë¦¬ì— ì—†ìœ¼ë©´ ë¡œë“œ ì‹œë„ (load_all_dataê°€ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´)
    if not all_contests_data and os.path.exists(DATA_FILE):
        load_all_data()
    return all_contests_data

def find_contest_by_id(contest_id):
    """
    ì£¼ì–´ì§„ ID (pblancId)ë¥¼ ê°€ì§„ ê³µê³ ë¥¼ ì°¾ì•„ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
    IDëŠ” ë¬¸ìì—´ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    global all_contests_data
    if not all_contests_data:
        load_all_data()
    
    str_contest_id = str(contest_id)
    for contest in all_contests_data: # all_contests_dataëŠ” ì´ì œ í•­ìƒ ë¦¬ìŠ¤íŠ¸
        if 'pblancId' in contest and str(contest['pblancId']) == str_contest_id:
            return contest
    return None

def add_contest(contest_data):
    """
    ìƒˆë¡œìš´ ê³µê³  ë°ì´í„°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    íŠ¸ëœì­ì…˜ ë°©ì‹ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì €ì¥í•˜ë©°, ì‹¤íŒ¨ ì‹œ ë¡¤ë°±ë©ë‹ˆë‹¤.
    """
    global all_contests_data
    
    print(f"\n[ADD_CONTEST] ==================== ê³µê³  ì¶”ê°€ ì‹œì‘ ====================")
    
    # 1. ì´ˆê¸° ë°ì´í„° ë¡œë“œ
    if not all_contests_data:
        print(f"[ADD_CONTEST] ë°ì´í„° ë¡œë“œ ì¤‘...")
        loaded_count = load_all_data()
        print(f"[ADD_CONTEST] ê¸°ì¡´ ë°ì´í„°: {loaded_count}ê°œ")

    original_data_count = len(all_contests_data)
    
    # 2. pblancId ìë™ ìƒì„±
    if 'pblancId' not in contest_data or not contest_data['pblancId']:
        contest_data['pblancId'] = str(uuid.uuid4())
        print(f"[ADD_CONTEST] ìë™ ìƒì„±ëœ ID: {contest_data['pblancId']}")

    # 3. ì¤‘ë³µ ê²€ì‚¬
    existing_contest = find_contest_by_id(contest_data.get('pblancId'))
    if existing_contest:
        print(f"[ERROR] ID {contest_data.get('pblancId')}ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return False
    
    # 4. ë°ì´í„° í‘œì¤€í™”
    try:
        standardized_data = _standardize_contest_data(contest_data)
        print(f"[ADD_CONTEST] ë°ì´í„° í‘œì¤€í™” ì™„ë£Œ")
    except Exception as e:
        print(f"[ERROR] ë°ì´í„° í‘œì¤€í™” ì‹¤íŒ¨: {e}")
        return False
    
    # 5. ë©”ëª¨ë¦¬ì— ì„ì‹œ ì¶”ê°€ (ë¡¤ë°± ê°€ëŠ¥í•œ ìƒíƒœ)
    all_contests_data.append(standardized_data)
    print(f"[ADD_CONTEST] ë©”ëª¨ë¦¬ì— ì„ì‹œ ì¶”ê°€ ({original_data_count} â†’ {len(all_contests_data)})")
    
    try:
        # 6. JSON íŒŒì¼ë“¤ì— ì €ì¥
        print(f"[ADD_CONTEST] JSON íŒŒì¼ ì €ì¥ ì‹œì‘...")
        save_success = _save_to_json_files(standardized_data)
        
        if not save_success:
            # ì €ì¥ ì‹¤íŒ¨ ì‹œ ë©”ëª¨ë¦¬ì—ì„œ ë¡¤ë°±
            print(f"[ROLLBACK] JSON ì €ì¥ ì‹¤íŒ¨ë¡œ ë©”ëª¨ë¦¬ì—ì„œ ì œê±°")
            all_contests_data.pop()
            print(f"[ROLLBACK] ë©”ëª¨ë¦¬ ë¡¤ë°± ì™„ë£Œ ({len(all_contests_data)}ê°œ)")
            return False
        
        print(f"[ADD_CONTEST] JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        
        # 7. Pinecone ì—…ë°ì´íŠ¸
        print(f"[ADD_CONTEST] Pinecone ì—…ë°ì´íŠ¸ ì‹œì‘...")
        pinecone_success = _update_pinecone_single(standardized_data)
        
        if not pinecone_success:
            print(f"[WARNING] Pinecone ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (JSON ë°ì´í„°ëŠ” ì €ì¥ë¨)")
        else:
            print(f"[ADD_CONTEST] Pinecone ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # 8. ì„±ê³µ ì™„ë£Œ
        print(f"[SUCCESS] ê³µê³  ì¶”ê°€ ì™„ë£Œ!")
        print(f"[SUCCESS] - ID: {standardized_data['pblancId']}")
        print(f"[SUCCESS] - ì œëª©: {standardized_data.get('title', 'N/A')}")
        print(f"[SUCCESS] - ì „ì²´ ë°ì´í„° ìˆ˜: {len(all_contests_data)}")
        print(f"[ADD_CONTEST] ==================== ê³µê³  ì¶”ê°€ ì™„ë£Œ ====================\n")
        
        return True
        
    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒ ì‹œ ë©”ëª¨ë¦¬ì—ì„œ ë¡¤ë°±
        print(f"[ERROR] ì˜ˆì™¸ ë°œìƒ: {e}")
        print(f"[ROLLBACK] ë©”ëª¨ë¦¬ì—ì„œ ë¡¤ë°± ì‹œë„...")
        
        try:
            if len(all_contests_data) > original_data_count:
                all_contests_data.pop()
                print(f"[ROLLBACK] ë©”ëª¨ë¦¬ ë¡¤ë°± ì™„ë£Œ ({len(all_contests_data)}ê°œ)")
            else:
                print(f"[ROLLBACK] ë¡¤ë°±í•  ë°ì´í„°ê°€ ì—†ìŒ")
        except Exception as rollback_error:
            print(f"[ERROR] ë¡¤ë°± ì¤‘ ì˜¤ë¥˜: {rollback_error}")
        
        print(f"[ADD_CONTEST] ==================== ê³µê³  ì¶”ê°€ ì‹¤íŒ¨ ====================\n")
        return False

def _standardize_contest_data(contest_data):
    """
    ìƒˆë¡œ ìƒì„±ëœ ë°ì´í„°ë¥¼ ê¸°ì¡´ í˜•ì‹ì— ë§ì¶° í‘œì¤€í™”í•©ë‹ˆë‹¤. (ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ í¬í•¨)
    """
    current_time = datetime.now().isoformat()
    
    standardized = {
        'pblancId': contest_data.get('pblancId'),
        'title': contest_data.get('title', ''),
        'org_name_ref': contest_data.get('organization', ''),
        'support_field': contest_data.get('category', ''),
        'region': contest_data.get('region', 'ì „êµ­'),
        'target_audience': contest_data.get('target_audience', 'ì œí•œ ì—†ìŒ'),
        'description': contest_data.get('description', ''),
        'deadline': contest_data.get('deadline', ''),
        'application_period': f"{datetime.now().strftime('%Y%m%d')} ~ {contest_data.get('deadline', '').replace('-', '')}",
        'contact': contest_data.get('contact', ''),
        'department': contest_data.get('organization', ''),
        'announcement_date': datetime.now().strftime('%Y-%m-%d'),
        'status': contest_data.get('status', 'active'),
        'created_at': contest_data.get('created_at', current_time),
        'updated_at': contest_data.get('updated_at', current_time),
        'announcement_number': f"USER-{datetime.now().strftime('%Y%m%d')}-{str(uuid.uuid4())[:8]}",
        'target_age': '',
        'startup_experience': '',
        'application_method': ['ì˜¨ë¼ì¸ ì‹ ì²­'],
        'submission_documents': [],
        'selection_procedure': [],
        'support_content': contest_data.get('budget', ''),
        'inquiry': [contest_data.get('contact', '')] if contest_data.get('contact') else [],
        'attachments': [],
        # ğŸ”¥ ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€ (RAG ì‹œìŠ¤í…œì—ì„œ êµ¬ë¶„ìš©)
        'data_source': 'user_created',
        'source_type': 'ì‚¬ìš©ì ìƒì„±',
        'is_user_generated': True
    }
    
    return standardized

def _save_to_json_files(contest_data):
    """
    í‘œì¤€í™”ëœ ë°ì´í„°ë¥¼ ê´€ë ¨ JSON íŒŒì¼ë“¤ì— íŠ¸ëœì­ì…˜ ë°©ì‹ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    print(f"\n[SAVE_FILES] ==================== JSON íŒŒì¼ ì €ì¥ ì‹œì‘ ====================")
    
    success_operations = []
    
    try:
        # 1. kstartup_contest_info.jsonì— ì €ì¥ (ì „ì²´ ë°ì´í„°)
        print(f"[SAVE_FILES] 1. kstartup_contest_info.json ì €ì¥ ì¤‘...")
        save_result = save_all_data()
        if save_result:
            success_operations.append("kstartup_contest_info")
            print(f"[SAVE_FILES] âœ“ kstartup_contest_info.json ì €ì¥ ì™„ë£Œ")
        else:
            print(f"[SAVE_FILES] âœ— kstartup_contest_info.json ì €ì¥ ì‹¤íŒ¨")
            return False
        
        # 2. announcements.jsonì— ì¶”ê°€/ì—…ë°ì´íŠ¸
        print(f"[SAVE_FILES] 2. announcements.json ì—…ë°ì´íŠ¸ ì¤‘...")
        announcements = load_json(ANNS_FILE, default={})
        original_count = len(announcements)
        
        announcements[str(contest_data['pblancId'])] = contest_data
        save_json(announcements, ANNS_FILE)
        success_operations.append("announcements")
        
        new_count = len(announcements)
        print(f"[SAVE_FILES] âœ“ announcements.json ì—…ë°ì´íŠ¸ ì™„ë£Œ ({original_count} â†’ {new_count})")
        
        # 3. organizations.json ì—…ë°ì´íŠ¸
        print(f"[SAVE_FILES] 3. organizations.json ì—…ë°ì´íŠ¸ ì¤‘...")
        organizations = load_json(ORGS_FILE, default={})
        org_name = contest_data.get('org_name_ref', '')
        
        if org_name:
            org_id = f"ORG_{org_name[:3].upper()}{len(org_name)}"
            if org_id not in organizations:
                organizations[org_id] = {
                    "name": org_name,
                    "type": "ì‚¬ìš©ì ìƒì„±",
                    "created_at": datetime.now().isoformat()
                }
                save_json(organizations, ORGS_FILE)
                print(f"[SAVE_FILES] âœ“ ìƒˆ ê¸°ê´€ ì¶”ê°€: {org_name}")
            else:
                print(f"[SAVE_FILES] â—‹ ê¸°ì¡´ ê¸°ê´€ ì‚¬ìš©: {org_name}")
        
        success_operations.append("organizations")
        
        # 4. index.json ì—…ë°ì´íŠ¸
        print(f"[SAVE_FILES] 4. index.json ì—…ë°ì´íŠ¸ ì¤‘...")
        index = load_json(INDEX_FILE, default={
            "title_keywords": {},
            "organization_name": {},
            "region": {},
            "support_field": {},
            "pbancSn_to_orgId": {}
        })
        
        # ê¸°ì¡´ ì¸ë±ìŠ¤ì—ì„œ í•´ë‹¹ ID ì œê±° (ì—…ë°ì´íŠ¸ ì‹œ)
        pblancId_str = str(contest_data['pblancId'])
        for keyword_list in index["title_keywords"].values():
            if pblancId_str in keyword_list:
                keyword_list.remove(pblancId_str)
        
        # ìƒˆë¡œìš´ í‚¤ì›Œë“œ ì¸ë±ì‹±
        title_tokens = tokenize(contest_data.get('title', ''))
        for token in title_tokens:
            if token not in index["title_keywords"]:
                index["title_keywords"][token] = []
            if pblancId_str not in index["title_keywords"][token]:
                index["title_keywords"][token].append(pblancId_str)
        
        # ê¸°ê´€ëª… ì¸ë±ì‹±
        if org_name:
            if org_name not in index["organization_name"]:
                index["organization_name"][org_name] = []
            if pblancId_str not in index["organization_name"][org_name]:
                index["organization_name"][org_name].append(pblancId_str)
        
        # ì§€ì—­ ì¸ë±ì‹±
        region = contest_data.get('region', '')
        if region:
            if region not in index["region"]:
                index["region"][region] = []
            if pblancId_str not in index["region"][region]:
                index["region"][region].append(pblancId_str)
        
        # ì§€ì›ë¶„ì•¼ ì¸ë±ì‹±
        support_field = contest_data.get('support_field', '')
        if support_field:
            if support_field not in index["support_field"]:
                index["support_field"][support_field] = []
            if pblancId_str not in index["support_field"][support_field]:
                index["support_field"][support_field].append(pblancId_str)
        
        save_json(index, INDEX_FILE)
        success_operations.append("index")
        print(f"[SAVE_FILES] âœ“ index.json ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        print(f"[SAVE_FILES] ==================== JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ ====================\n")
        return True
        
    except Exception as e:
        print(f"[SAVE_FILES] âœ— JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"[SAVE_FILES] ì„±ê³µí•œ ì‘ì—…: {', '.join(success_operations)}")
        print(f"[SAVE_FILES] ==================== JSON íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ ====================\n")
        return False

def _update_pinecone_single(contest_data):
    """
    ë‹¨ì¼ ê³µê³  ë°ì´í„°ë¥¼ Pineconeì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. (ê°œì„ ëœ ë©”íƒ€ë°ì´í„° ì‚¬ìš©)
    """
    try:
        # RAG ì‹œìŠ¤í…œì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        try:
            from rag_system import get_rag_chatbot, _build_announcement_text, _build_announcement_metadata
            chatbot = get_rag_chatbot()
            
            if not chatbot.embedding_manager.model or not chatbot.pinecone_manager.index:
                print("Warning: RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ Pinecone ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                return False
                
        except ImportError:
            print("Warning: RAG ì‹œìŠ¤í…œì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ Pinecone ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        
        # ê°œì„ ëœ í…ìŠ¤íŠ¸ ë‚´ìš© êµ¬ì„± (ëª¨ë“  ë©”íƒ€ë°ì´í„° í¬í•¨)
        text_content = _build_announcement_text(contest_data)
        
        if not text_content.strip():
            print("Warning: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ì„ë² ë”© ìƒì„±
        embedding = chatbot.embedding_manager.create_embedding(text_content)
        
        # ê°œì„ ëœ ë©”íƒ€ë°ì´í„° êµ¬ì„± (í™•ì¥ëœ ì •ë³´ í¬í•¨)
        metadata = _build_announcement_metadata(contest_data)
        
        # ë²¡í„° ë°ì´í„° êµ¬ì„±
        vector_id = f"announcement_{contest_data.get('pblancId', contest_data.get('id', 'unknown'))}"
        vector_data = [{
            "id": vector_id,
            "values": embedding,
            "metadata": metadata
        }]
        
        # Pineconeì— ì—…ì„œíŠ¸
        success = chatbot.pinecone_manager.upsert_vectors(vector_data)
        
        if success:
            print(f"Pinecone ì—…ë°ì´íŠ¸ ì„±ê³µ: {vector_id}")
        else:
            print(f"Pinecone ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {vector_id}")
            
        return success
        
    except Exception as e:
        print(f"Pinecone ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def update_contest(contest_id, updated_data):
    """
    ê¸°ì¡´ ê³µê³  ë°ì´í„°ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. (ì™„ì „ ì¬êµ¬í˜„)
    contest_idë¥¼ ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì°¾ì•„ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    global all_contests_data
    
    # ê°•ì œë¡œ ìµœì‹  ë°ì´í„° ë¡œë“œ
    load_all_data()
    
    if not all_contests_data:
        print(f"[ERROR] ì „ì²´ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return False
    
    str_contest_id = str(contest_id)
    print(f"\n[UPDATE] ==================== ìˆ˜ì • ì‹œì‘ ====================")
    print(f"[UPDATE] ì…ë ¥ ID: '{str_contest_id}'")
    print(f"[UPDATE] ì „ì²´ ë°ì´í„° ìˆ˜: {len(all_contests_data)}")
    print(f"[UPDATE] ì—…ë°ì´íŠ¸ í•„ë“œ: {list(updated_data.keys())}")
    
    # ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ í™•ì¸
    if all_contests_data:
        sample = all_contests_data[0]
        print(f"[UPDATE] ìƒ˜í”Œ ë°ì´í„° í‚¤: {list(sample.keys())[:15]}")
        print(f"[UPDATE] ìƒ˜í”Œ pblancId: '{sample.get('pblancId', 'N/A')}'")
        print(f"[UPDATE] ìƒ˜í”Œ title: '{sample.get('title', 'N/A')}'")
    
    # ëª¨ë“  ê°€ëŠ¥í•œ ë°©ë²•ìœ¼ë¡œ ë°ì´í„° ì°¾ê¸°
    found_index = None
    found_data = None
    search_method = None
    
    # === ë°©ë²• 1: pblancId í•„ë“œë¡œ ì •í™•íˆ ë§¤ì¹­ ===
    print(f"\n[SEARCH] ë°©ë²• 1: pblancId ì •í™• ë§¤ì¹­")
    for idx, item in enumerate(all_contests_data):
        item_id = item.get('pblancId')
        if item_id is not None and str(item_id) == str_contest_id:
            found_index = idx
            found_data = item
            search_method = f"pblancId ì •í™• ë§¤ì¹­ (Index: {idx})"
            print(f"[SEARCH] âœ“ ë°©ë²• 1 ì„±ê³µ: Index {idx}, pblancId '{item_id}'")
            break
    
    # === ë°©ë²• 2: ìˆ«ì ì¸ë±ìŠ¤ë¡œ ì§ì ‘ ì ‘ê·¼ ===
    if found_index is None:
        print(f"[SEARCH] ë°©ë²• 2: ìˆ«ì ì¸ë±ìŠ¤ ì ‘ê·¼")
        try:
            idx_num = int(str_contest_id)
            if 0 <= idx_num < len(all_contests_data):
                found_index = idx_num
                found_data = all_contests_data[idx_num]
                search_method = f"ì¸ë±ìŠ¤ ì§ì ‘ ì ‘ê·¼ (Index: {idx_num})"
                print(f"[SEARCH] âœ“ ë°©ë²• 2 ì„±ê³µ: Index {idx_num}")
                print(f"[SEARCH] í•´ë‹¹ ë°ì´í„° pblancId: '{found_data.get('pblancId', 'N/A')}'")
            else:
                print(f"[SEARCH] âœ— ë°©ë²• 2 ì‹¤íŒ¨: ì¸ë±ìŠ¤ {idx_num}ì´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨")
        except (ValueError, TypeError):
            print(f"[SEARCH] âœ— ë°©ë²• 2 ì‹¤íŒ¨: '{str_contest_id}'ë¥¼ ìˆ«ìë¡œ ë³€í™˜ ë¶ˆê°€")
    
    # === ë°©ë²• 3: ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ (pblancId, title ë“±) ===
    if found_index is None:
        print(f"[SEARCH] ë°©ë²• 3: ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­")
        search_fields = ['pblancId', 'title', 'id']
        for field in search_fields:
            for idx, item in enumerate(all_contests_data):
                field_value = item.get(field, '')
                if field_value and str_contest_id in str(field_value):
                    found_index = idx
                    found_data = item
                    search_method = f"{field} í•„ë“œ ë¶€ë¶„ ë§¤ì¹­ (Index: {idx})"
                    print(f"[SEARCH] âœ“ ë°©ë²• 3 ì„±ê³µ: {field} í•„ë“œì—ì„œ '{field_value}' ë§¤ì¹­")
                    break
            if found_index is not None:
                break
    
    # === ë°©ë²• 4: UUID í˜•íƒœ ID ë§¤ì¹­ ===
    if found_index is None:
        print(f"[SEARCH] ë°©ë²• 4: UUID í˜•íƒœ ë§¤ì¹­")
        for idx, item in enumerate(all_contests_data):
            item_id = item.get('pblancId', '')
            if item_id and len(str(item_id)) > 10 and str_contest_id in str(item_id):
                found_index = idx
                found_data = item
                search_method = f"UUID ë¶€ë¶„ ë§¤ì¹­ (Index: {idx})"
                print(f"[SEARCH] âœ“ ë°©ë²• 4 ì„±ê³µ: UUID '{item_id}' ë¶€ë¶„ ë§¤ì¹­")
                break
    
    # === ê²°ê³¼ í™•ì¸ ë° ì—…ë°ì´íŠ¸ ===
    if found_index is not None and found_data is not None:
        print(f"\n[SUCCESS] ë°ì´í„° ì°¾ê¸° ì„±ê³µ!")
        print(f"[SUCCESS] ê²€ìƒ‰ ë°©ë²•: {search_method}")
        print(f"[SUCCESS] ì¸ë±ìŠ¤: {found_index}")
        print(f"[SUCCESS] ì›ë³¸ pblancId: '{found_data.get('pblancId', 'N/A')}'")
        print(f"[SUCCESS] ì›ë³¸ title: '{found_data.get('title', 'N/A')}'")
        
        # ì›ë³¸ ID ë³´ì¡´
        original_pblancId = found_data.get('pblancId', str_contest_id)
        
        # ì—…ë°ì´íŠ¸ ì‹œê°„ ì¶”ê°€
        updated_data['updated_at'] = datetime.now().isoformat()
        
        # ë°ì´í„° ë³‘í•© (ê¸°ì¡´ ë°ì´í„° ë³´ì¡´í•˜ë©´ì„œ ìƒˆ ë°ì´í„° ì¶”ê°€)
        merged_data = found_data.copy()
        for key, value in updated_data.items():
            if key != 'pblancId':  # IDëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŒ
                merged_data[key] = value
        merged_data['pblancId'] = original_pblancId  # ID ë³´ì¡´
        
        print(f"[UPDATE] ë³‘í•©ëœ ë°ì´í„° í•„ë“œ ìˆ˜: {len(merged_data)}")
        print(f"[UPDATE] ë³€ê²½ëœ í•„ë“œ: {[k for k in updated_data.keys() if k != 'updated_at']}")
        
        # ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        all_contests_data[found_index] = merged_data
        print(f"[UPDATE] ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # JSON íŒŒì¼ ì €ì¥
        try:
            save_success = _save_to_json_files(merged_data)
            if save_success:
                print(f"[UPDATE] JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ")
            else:
                print(f"[ERROR] JSON íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
                return False
        except Exception as e:
            print(f"[ERROR] JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
        
        # Pinecone ì—…ë°ì´íŠ¸
        try:
            pinecone_success = _update_pinecone_single(merged_data)
            if pinecone_success:
                print(f"[UPDATE] Pinecone ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            else:
                print(f"[WARNING] Pinecone ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (JSONì€ ì €ì¥ë¨)")
        except Exception as e:
            print(f"[WARNING] Pinecone ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        print(f"[SUCCESS] ==================== ìˆ˜ì • ì™„ë£Œ ====================\n")
        return True
    
    else:
        print(f"\n[FAILURE] ==================== ìˆ˜ì • ì‹¤íŒ¨ ====================")
        print(f"[FAILURE] ID '{str_contest_id}'ë¡œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë””ë²„ê¹…ì„ ìœ„í•´ ì‹¤ì œ ì €ì¥ëœ IDë“¤ ì¶œë ¥
        print(f"[DEBUG] ì‹¤ì œ ì €ì¥ëœ IDë“¤ (ì²˜ìŒ 10ê°œ):")
        for i, item in enumerate(all_contests_data[:10]):
            pblancId = item.get('pblancId', 'N/A')
            title = item.get('title', 'N/A')[:30]
            print(f"[DEBUG]   [{i}] pblancId: '{pblancId}', title: '{title}'")
        
        print(f"[FAILURE] ==========================================\n")
        return False

def delete_contest(contest_id):
    """
    ì£¼ì–´ì§„ ID (pblancId)ë¥¼ ê°€ì§„ ê³µê³ ë¥¼ ì•ˆì „í•˜ê²Œ ì‚­ì œí•©ë‹ˆë‹¤.
    ë°±ì—… ìƒì„± í›„ ì‚­ì œí•˜ë©°, ì‹¤íŒ¨ ì‹œ ë³µêµ¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    """
    global all_contests_data
    
    print(f"\n[DELETE_CONTEST] ==================== ê³µê³  ì‚­ì œ ì‹œì‘ ====================")
    
    if not all_contests_data:
        print(f"[DELETE_CONTEST] ë°ì´í„° ë¡œë“œ ì¤‘...")
        load_all_data()

    str_contest_id = str(contest_id)
    original_length = len(all_contests_data)
    print(f"[DELETE_CONTEST] ì‚­ì œ ëŒ€ìƒ ID: {str_contest_id}")
    print(f"[DELETE_CONTEST] í˜„ì¬ ë°ì´í„° ìˆ˜: {original_length}")
    
    # 1. ì‚­ì œí•  ë°ì´í„° ì°¾ê¸° ë° ë°±ì—…
    deleted_data = None
    deleted_index = None
    
    for idx, contest in enumerate(all_contests_data):
        if 'pblancId' in contest and str(contest['pblancId']) == str_contest_id:
            deleted_data = contest.copy()  # ë°±ì—…ìš© ë³µì‚¬ë³¸
            deleted_index = idx
            print(f"[DELETE_CONTEST] ì‚­ì œ ëŒ€ìƒ ë°œê²¬: {contest.get('title', 'N/A')}")
            break
    
    if deleted_data is None:
        print(f"[ERROR] ID {str_contest_id}ë¥¼ ê°€ì§„ ê³µê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"[DELETE_CONTEST] ==================== ê³µê³  ì‚­ì œ ì‹¤íŒ¨ ====================\n")
        return False
    
    try:
        # 2. ë©”ëª¨ë¦¬ì—ì„œ ì œê±°
        all_contests_data.pop(deleted_index)
        print(f"[DELETE_CONTEST] ë©”ëª¨ë¦¬ì—ì„œ ì œê±° ì™„ë£Œ ({original_length} â†’ {len(all_contests_data)})")
        
        # 3. JSON íŒŒì¼ë“¤ ì—…ë°ì´íŠ¸
        print(f"[DELETE_CONTEST] JSON íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹œì‘...")
        
        # 3-1. kstartup_contest_info.json ì—…ë°ì´íŠ¸
        save_result = save_all_data()
        if not save_result:
            raise Exception("kstartup_contest_info.json ì €ì¥ ì‹¤íŒ¨")
        
        # 3-2. announcements.jsonì—ì„œ ì‚­ì œ
        try:
            announcements = load_json(ANNS_FILE, default={})
            if str_contest_id in announcements:
                del announcements[str_contest_id]
                save_json(announcements, ANNS_FILE)
                print(f"[DELETE_CONTEST] announcements.jsonì—ì„œ ì œê±° ì™„ë£Œ")
            else:
                print(f"[WARNING] announcements.jsonì— ID {str_contest_id}ê°€ ì—†ìŒ")
        except Exception as e:
            print(f"[WARNING] announcements.json ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        
        # 3-3. index.jsonì—ì„œ ê´€ë ¨ ì¸ë±ìŠ¤ ì •ë¦¬
        try:
            index = load_json(INDEX_FILE, default={
                "title_keywords": {},
                "organization_name": {},
                "region": {},
                "support_field": {},
                "pbancSn_to_orgId": {}
            })
            
            # ëª¨ë“  ì¸ë±ìŠ¤ì—ì„œ í•´ë‹¹ ID ì œê±°
            index_updated = False
            
            # í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ì •ë¦¬
            for keyword, id_list in list(index["title_keywords"].items()):
                if str_contest_id in id_list:
                    id_list.remove(str_contest_id)
                    index_updated = True
                    if not id_list:  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ì´ë©´ í‚¤ì›Œë“œ ìì²´ ì œê±°
                        del index["title_keywords"][keyword]
            
            # ê¸°ê´€ëª… ì¸ë±ìŠ¤ ì •ë¦¬
            for org_name, id_list in list(index["organization_name"].items()):
                if str_contest_id in id_list:
                    id_list.remove(str_contest_id)
                    index_updated = True
                    if not id_list:
                        del index["organization_name"][org_name]
            
            # ì§€ì—­ ì¸ë±ìŠ¤ ì •ë¦¬
            for region, id_list in list(index["region"].items()):
                if str_contest_id in id_list:
                    id_list.remove(str_contest_id)
                    index_updated = True
                    if not id_list:
                        del index["region"][region]
            
            # ì§€ì›ë¶„ì•¼ ì¸ë±ìŠ¤ ì •ë¦¬
            for field, id_list in list(index["support_field"].items()):
                if str_contest_id in id_list:
                    id_list.remove(str_contest_id)
                    index_updated = True
                    if not id_list:
                        del index["support_field"][field]
            
            # pbancSn_to_orgId ì¸ë±ìŠ¤ ì •ë¦¬
            if str_contest_id in index["pbancSn_to_orgId"]:
                del index["pbancSn_to_orgId"][str_contest_id]
                index_updated = True
            
            if index_updated:
                save_json(index, INDEX_FILE)
                print(f"[DELETE_CONTEST] index.json ì •ë¦¬ ì™„ë£Œ")
            else:
                print(f"[DELETE_CONTEST] index.jsonì— ë³€ê²½ì‚¬í•­ ì—†ìŒ")
                
        except Exception as e:
            print(f"[WARNING] index.json ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        
        # 4. Pineconeì—ì„œ ì‚­ì œ
        print(f"[DELETE_CONTEST] Pineconeì—ì„œ ì‚­ì œ ì‹œë„...")
        pinecone_success = _delete_from_pinecone(str_contest_id)
        if not pinecone_success:
            print(f"[WARNING] Pinecone ì‚­ì œ ì‹¤íŒ¨ (JSON ë°ì´í„°ëŠ” ì‚­ì œë¨)")
        else:
            print(f"[DELETE_CONTEST] Pinecone ì‚­ì œ ì™„ë£Œ")
        
        # 5. ì„±ê³µ ì™„ë£Œ
        print(f"[SUCCESS] ê³µê³  ì‚­ì œ ì™„ë£Œ!")
        print(f"[SUCCESS] - ì‚­ì œëœ ID: {str_contest_id}")
        print(f"[SUCCESS] - ì‚­ì œëœ ì œëª©: {deleted_data.get('title', 'N/A')}")
        print(f"[SUCCESS] - ë‚¨ì€ ë°ì´í„° ìˆ˜: {len(all_contests_data)}")
        print(f"[DELETE_CONTEST] ==================== ê³µê³  ì‚­ì œ ì™„ë£Œ ====================\n")
        
        return True
        
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ëª¨ë¦¬ ë³µêµ¬
        print(f"[ERROR] ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"[RECOVERY] ë©”ëª¨ë¦¬ ë³µêµ¬ ì‹œë„...")
        
        try:
            if deleted_data and deleted_index is not None:
                all_contests_data.insert(deleted_index, deleted_data)
                print(f"[RECOVERY] ë©”ëª¨ë¦¬ ë³µêµ¬ ì™„ë£Œ ({len(all_contests_data)}ê°œ)")
            else:
                print(f"[ERROR] ë³µêµ¬í•  ë°ì´í„°ê°€ ì—†ìŒ")
        except Exception as recovery_error:
            print(f"[ERROR] ë©”ëª¨ë¦¬ ë³µêµ¬ ì‹¤íŒ¨: {recovery_error}")
        
        print(f"[DELETE_CONTEST] ==================== ê³µê³  ì‚­ì œ ì‹¤íŒ¨ ====================\n")
        return False

def _delete_from_pinecone(contest_id):
    """
    Pineconeì—ì„œ ê³µê³  ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
    """
    try:
        # RAG ì‹œìŠ¤í…œì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        try:
            from rag_system import get_rag_chatbot
            chatbot = get_rag_chatbot()
            
            if not chatbot.pinecone_manager.index:
                print("Warning: Pinecone ì¸ë±ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì‚­ì œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                return False
                
        except ImportError:
            print("Warning: RAG ì‹œìŠ¤í…œì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ Pinecone ì‚­ì œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        
        # ë²¡í„° ID êµ¬ì„±
        vector_id = f"announcement_{contest_id}"
        
        # Pineconeì—ì„œ ì‚­ì œ
        success = chatbot.pinecone_manager.delete_vectors([vector_id])
        
        if success:
            print(f"Pinecone ì‚­ì œ ì„±ê³µ: {vector_id}")
        else:
            print(f"Pinecone ì‚­ì œ ì‹¤íŒ¨: {vector_id}")
            
        return success
        
    except Exception as e:
        print(f"Pinecone ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def search_contests(keyword, search_fields=None):
    """
    ì§€ì •ëœ í•„ë“œ ë˜ëŠ” ì „ì²´ í•„ë“œì—ì„œ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ê³µê³ ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    search_fieldsê°€ Noneì´ë©´ ëª¨ë“  ë¬¸ìì—´ íƒ€ì…ì˜ ê°’ì„ ê²€ìƒ‰ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤.
    """
    global all_contests_data
    if not all_contests_data:
        load_all_data()
    
    results = []
    lower_keyword = keyword.lower()

    # ê²€ìƒ‰ ëŒ€ìƒ í•„ë“œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë©´, ëª¨ë“  í‚¤ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•¨
    effective_search_fields = search_fields
    if not search_fields:
        # ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì²« ë²ˆì§¸ ì•„ì´í…œì˜ í‚¤ë“¤ì„ ì‚¬ìš© (ëª¨ë“  ì•„ì´í…œì´ ë™ì¼í•œ í‚¤ë¥¼ ê°€ì§„ë‹¤ê³  ê°€ì •)
        if all_contests_data:
            effective_search_fields = list(all_contests_data[0].keys())
        else: # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê²€ìƒ‰ ë¶ˆê°€
            return []
            
    for contest in all_contests_data:
        for field in effective_search_fields:
            if field in contest and isinstance(contest[field], str):
                if lower_keyword in contest[field].lower():
                    results.append(contest)
                    break # í˜„ì¬ ê³µê³ ëŠ” ì´ë¯¸ ì¶”ê°€ë˜ì—ˆìœ¼ë¯€ë¡œ ë‹¤ìŒ ê³µê³ ë¡œ ë„˜ì–´ê°
    return results

# í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ ë°ì´í„° ë¡œë“œ (app.pyì—ì„œ data_handler ì„í¬íŠ¸ ì‹œ ì‹¤í–‰ë¨)
load_all_data()

if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ (ì„ íƒ ì‚¬í•­)
    print("data_handler.py í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # ì´ˆê¸° ë°ì´í„° ë¡œë“œ í™•ì¸ (load_all_dataê°€ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ì—ˆì„ ê²ƒì„)
    print(f"ì´ˆê¸° ë¡œë“œëœ ê³µê³  ìˆ˜: {len(get_all_contests())}")
    if get_all_contests():
        print(f"ì²«ë²ˆì§¸ ê³µê³  ìƒ˜í”Œ: {list(get_all_contests())[0] if get_all_contests() else 'ì—†ìŒ'}")


    # kstartup_contest_info.json íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜, í…ŒìŠ¤íŠ¸ IDê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ.
    # í…ŒìŠ¤íŠ¸ ì „ íŒŒì¼ì„ ì •ë¦¬í•˜ê±°ë‚˜ ê³ ìœ í•œ í…ŒìŠ¤íŠ¸ ID ì‚¬ìš© ê¶Œì¥.

    # ìƒ˜í”Œ ë°ì´í„° ì¶”ê°€
    sample_contest_1 = {
        "pblancId": f"TESTID_{uuid.uuid4()}", 
        "pblancNm": "í…ŒìŠ¤íŠ¸ ê³µê³  1 (í•¸ë“¤ëŸ¬)",
        "plBizNm": "í…ŒìŠ¤íŠ¸ ì‚¬ì—… 1", "pblancUrl": "http://example.com/test001",
        "rcptEngNm": "í…ŒìŠ¤íŠ¸ê¸°ê´€A", "reqstBeginDt": "20240101", "reqstEndDt": "20240131"
    }
    sample_contest_2 = {
        "pblancId": f"TESTID_{uuid.uuid4()}",
        "pblancNm": "ë‘ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ê³µê³  (í•¸ë“¤ëŸ¬)",
        "plBizNm": "í…ŒìŠ¤íŠ¸ ì‚¬ì—… 2", "pblancUrl": "http://example.com/test002",
        "rcptEngNm": "í…ŒìŠ¤íŠ¸ê¸°ê´€B", "reqstBeginDt": "20240201", "reqstEndDt": "20240228"
    }
    
    print("\n--- ê³µê³  ì¶”ê°€ í…ŒìŠ¤íŠ¸ ---")
    added1 = add_contest(sample_contest_1)
    print(f"{sample_contest_1['pblancId']} ì¶”ê°€ ê²°ê³¼: {'ì„±ê³µ' if added1 else 'ì‹¤íŒ¨'}")
    added2 = add_contest(sample_contest_2)
    print(f"{sample_contest_2['pblancId']} ì¶”ê°€ ê²°ê³¼: {'ì„±ê³µ' if added2 else 'ì‹¤íŒ¨'}")
    
    print(f"ì¶”ê°€ í›„ ê³µê³  ìˆ˜: {len(get_all_contests())}")

    print("\n--- ê³µê³  ì¡°íšŒ í…ŒìŠ¤íŠ¸ ---")
    if added1:
        found_contest = find_contest_by_id(sample_contest_1["pblancId"])
        print(f"{sample_contest_1['pblancId']} ì°¾ìŒ: {found_contest.get('pblancNm') if found_contest else 'ëª»ì°¾ìŒ'}")

    print("\n--- ê³µê³  ìˆ˜ì • í…ŒìŠ¤íŠ¸ ---")
    if added1:
        update_data = {"pblancNm": "ìˆ˜ì •ëœ í…ŒìŠ¤íŠ¸ ê³µê³  1 (í•¸ë“¤ëŸ¬)", "rcptEngNm": "í…ŒìŠ¤íŠ¸ê¸°ê´€AA"}
        updated = update_contest(sample_contest_1["pblancId"], update_data)
        print(f"{sample_contest_1['pblancId']} ìˆ˜ì • ê²°ê³¼: {'ì„±ê³µ' if updated else 'ì‹¤íŒ¨'}")
        if updated:
            updated_c = find_contest_by_id(sample_contest_1["pblancId"])
            print(f"ìˆ˜ì •ëœ ë‚´ìš©: {updated_c.get('pblancNm')}, {updated_c.get('rcptEngNm')}")

    print("\n--- ê³µê³  ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ì‚¬ì—…ëª…) ---")
    search_results_biz = search_contests("í…ŒìŠ¤íŠ¸ ì‚¬ì—…", search_fields=['plBizNm', 'pblancNm'])
    print(f"'í…ŒìŠ¤íŠ¸ ì‚¬ì—…' ê²€ìƒ‰ ê²°ê³¼ (ì‚¬ì—…ëª…, ê³µê³ ëª…): {len(search_results_biz)}ê±´")
    for r in search_results_biz:
        print(f"  - {r.get('pblancId')}: {r.get('pblancNm')}")
        
    print("\n--- ê³µê³  ì‚­ì œ í…ŒìŠ¤íŠ¸ ---")
    if added2:
        deleted = delete_contest(sample_contest_2["pblancId"])
        print(f"{sample_contest_2['pblancId']} ì‚­ì œ ê²°ê³¼: {'ì„±ê³µ' if deleted else 'ì‹¤íŒ¨'}")
        
    print(f"ì‚­ì œ í›„ ê³µê³  ìˆ˜: {len(get_all_contests())}")
    
    print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ. kstartup_contest_info.json íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    print("ì €ì¥ëœ íŒŒì¼ì€ IDë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.")
    print("get_all_contests()ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.")

    # í™•ì¸ìš©: í˜„ì¬ ë©”ëª¨ë¦¬(all_contests_data)ì™€ íŒŒì¼ ë‚´ìš© ë¹„êµ
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            file_content_type = type(json.load(f))
            print(f"{DATA_FILE}ì˜ ìµœìƒìœ„ íƒ€ì…: {file_content_type}")
    print(f"get_all_contests() ë°˜í™˜ íƒ€ì…: {type(get_all_contests())}")
    if get_all_contests():
         print(f"get_all_contests() ì²«ë²ˆì§¸ ì•„ì´í…œ íƒ€ì…: {type(get_all_contests()[0])}") 